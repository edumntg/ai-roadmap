{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get housing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target\n",
    "\n",
    "X = torch.as_tensor(X, dtype = torch.float)\n",
    "y = torch.as_tensor(y, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-14.4313], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 32),\n",
    "    nn.Linear(32, 64),\n",
    "    nn.Linear(64, 128),\n",
    "    nn.Linear(128, 64),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "# Test architecture\n",
    "model(X_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, train_loss: 0.063561, val_loss: 0.000379\n",
      "Epoch 2, train_loss: 0.000175, val_loss: 0.000278\n",
      "Epoch 3, train_loss: 0.000136, val_loss: 0.000277\n",
      "Epoch 4, train_loss: 0.000136, val_loss: 0.000277\n",
      "Epoch 5, train_loss: 0.000136, val_loss: 0.000277\n",
      "Epoch 6, train_loss: 0.000136, val_loss: 0.000277\n",
      "Epoch 7, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 8, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 9, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 10, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 11, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 12, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 13, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 14, train_loss: 0.000136, val_loss: 0.000276\n",
      "Epoch 15, train_loss: 0.000135, val_loss: 0.000276\n",
      "Epoch 16, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 17, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 18, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 19, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 20, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 21, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 22, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 23, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 24, train_loss: 0.000135, val_loss: 0.000275\n",
      "Epoch 25, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 26, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 27, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 28, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 29, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 30, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 31, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 32, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 33, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 34, train_loss: 0.000135, val_loss: 0.000274\n",
      "Epoch 35, train_loss: 0.000135, val_loss: 0.000273\n",
      "Epoch 36, train_loss: 0.000135, val_loss: 0.000273\n",
      "Epoch 37, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 38, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 39, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 40, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 41, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 42, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 43, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 44, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 45, train_loss: 0.000134, val_loss: 0.000273\n",
      "Epoch 46, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 47, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 48, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 49, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 50, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 51, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 52, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 53, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 54, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 55, train_loss: 0.000134, val_loss: 0.000272\n",
      "Epoch 56, train_loss: 0.000134, val_loss: 0.000271\n",
      "Epoch 57, train_loss: 0.000134, val_loss: 0.000271\n",
      "Epoch 58, train_loss: 0.000134, val_loss: 0.000271\n",
      "Epoch 59, train_loss: 0.000134, val_loss: 0.000271\n",
      "Epoch 60, train_loss: 0.000134, val_loss: 0.000271\n",
      "Epoch 61, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 62, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 63, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 64, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 65, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 66, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 67, train_loss: 0.000133, val_loss: 0.000271\n",
      "Epoch 68, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 69, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 70, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 71, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 72, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 73, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 74, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 75, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 76, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 77, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 78, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 79, train_loss: 0.000133, val_loss: 0.000270\n",
      "Epoch 80, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 81, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 82, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 83, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 84, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 85, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 86, train_loss: 0.000133, val_loss: 0.000269\n",
      "Epoch 87, train_loss: 0.000132, val_loss: 0.000269\n",
      "Epoch 88, train_loss: 0.000132, val_loss: 0.000269\n",
      "Epoch 89, train_loss: 0.000132, val_loss: 0.000269\n",
      "Epoch 90, train_loss: 0.000132, val_loss: 0.000269\n",
      "Epoch 91, train_loss: 0.000132, val_loss: 0.000269\n",
      "Epoch 92, train_loss: 0.000132, val_loss: 0.000269\n",
      "Epoch 93, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 94, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 95, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 96, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 97, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 98, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 99, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 100, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 101, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 102, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 103, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 104, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 105, train_loss: 0.000132, val_loss: 0.000268\n",
      "Epoch 106, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 107, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 108, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 109, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 110, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 111, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 112, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 113, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 114, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 115, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 116, train_loss: 0.000132, val_loss: 0.000267\n",
      "Epoch 117, train_loss: 0.000131, val_loss: 0.000267\n",
      "Epoch 118, train_loss: 0.000131, val_loss: 0.000267\n",
      "Epoch 119, train_loss: 0.000131, val_loss: 0.000267\n",
      "Epoch 120, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 121, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 122, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 123, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 124, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 125, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 126, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 127, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 128, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 129, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 130, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 131, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 132, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 133, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 134, train_loss: 0.000131, val_loss: 0.000266\n",
      "Epoch 135, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 136, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 137, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 138, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 139, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 140, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 141, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 142, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 143, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 144, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 145, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 146, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 147, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 148, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 149, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 150, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 151, train_loss: 0.000131, val_loss: 0.000265\n",
      "Epoch 152, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 153, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 154, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 155, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 156, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 157, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 158, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 159, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 160, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 161, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 162, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 163, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 164, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 165, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 166, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 167, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 168, train_loss: 0.000130, val_loss: 0.000264\n",
      "Epoch 169, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 170, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 171, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 172, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 173, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 174, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 175, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 176, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 177, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 178, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 179, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 180, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 181, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 182, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 183, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 184, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 185, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 186, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 187, train_loss: 0.000130, val_loss: 0.000263\n",
      "Epoch 188, train_loss: 0.000130, val_loss: 0.000262\n",
      "Epoch 189, train_loss: 0.000130, val_loss: 0.000262\n",
      "Epoch 190, train_loss: 0.000130, val_loss: 0.000262\n",
      "Epoch 191, train_loss: 0.000130, val_loss: 0.000262\n",
      "Epoch 192, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 193, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 194, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 195, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 196, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 197, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 198, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 199, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 200, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 201, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 202, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 203, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 204, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 205, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 206, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 207, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 208, train_loss: 0.000129, val_loss: 0.000262\n",
      "Epoch 209, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 210, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 211, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 212, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 213, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 214, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 215, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 216, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 217, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 218, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 219, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 220, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 221, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 222, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 223, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 224, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 225, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 226, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 227, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 228, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 229, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 230, train_loss: 0.000129, val_loss: 0.000261\n",
      "Epoch 231, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 232, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 233, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 234, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 235, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 236, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 237, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 238, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 239, train_loss: 0.000129, val_loss: 0.000260\n",
      "Epoch 240, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 241, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 242, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 243, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 244, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 245, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 246, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 247, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 248, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 249, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 250, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 251, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 252, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 253, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 254, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 255, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 256, train_loss: 0.000128, val_loss: 0.000260\n",
      "Epoch 257, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 258, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 259, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 260, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 261, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 262, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 263, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 264, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 265, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 266, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 267, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 268, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 269, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 270, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 271, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 272, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 273, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 274, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 275, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 276, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 277, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 278, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 279, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 280, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 281, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 282, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 283, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 284, train_loss: 0.000128, val_loss: 0.000259\n",
      "Epoch 285, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 286, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 287, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 288, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 289, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 290, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 291, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 292, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 293, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 294, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 295, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 296, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 297, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 298, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 299, train_loss: 0.000128, val_loss: 0.000258\n",
      "Epoch 300, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 301, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 302, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 303, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 304, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 305, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 306, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 307, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 308, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 309, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 310, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 311, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 312, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 313, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 314, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 315, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 316, train_loss: 0.000127, val_loss: 0.000258\n",
      "Epoch 317, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 318, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 319, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 320, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 321, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 322, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 323, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 324, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 325, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 326, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 327, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 328, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 329, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 330, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 331, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 332, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 333, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 334, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 335, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 336, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 337, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 338, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 339, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 340, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 341, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 342, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 343, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 344, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 345, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 346, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 347, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 348, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 349, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 350, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 351, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 352, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 353, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 354, train_loss: 0.000127, val_loss: 0.000257\n",
      "Epoch 355, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 356, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 357, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 358, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 359, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 360, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 361, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 362, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 363, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 364, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 365, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 366, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 367, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 368, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 369, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 370, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 371, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 372, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 373, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 374, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 375, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 376, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 377, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 378, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 379, train_loss: 0.000127, val_loss: 0.000256\n",
      "Epoch 380, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 381, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 382, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 383, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 384, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 385, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 386, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 387, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 388, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 389, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 390, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 391, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 392, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 393, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 394, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 395, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 396, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 397, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 398, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 399, train_loss: 0.000126, val_loss: 0.000256\n",
      "Epoch 400, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 401, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 402, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 403, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 404, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 405, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 406, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 407, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 408, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 409, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 410, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 411, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 412, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 413, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 414, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 415, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 416, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 417, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 418, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 419, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 420, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 421, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 422, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 423, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 424, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 425, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 426, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 427, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 428, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 429, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 430, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 431, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 432, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 433, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 434, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 435, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 436, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 437, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 438, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 439, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 440, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 441, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 442, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 443, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 444, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 445, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 446, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 447, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 448, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 449, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 450, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 451, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 452, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 453, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 454, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 455, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 456, train_loss: 0.000126, val_loss: 0.000255\n",
      "Epoch 457, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 458, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 459, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 460, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 461, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 462, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 463, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 464, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 465, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 466, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 467, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 468, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 469, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 470, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 471, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 472, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 473, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 474, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 475, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 476, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 477, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 478, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 479, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 480, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 481, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 482, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 483, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 484, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 485, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 486, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 487, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 488, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 489, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 490, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 491, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 492, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 493, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 494, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 495, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 496, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 497, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 498, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 499, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 500, train_loss: 0.000126, val_loss: 0.000254\n",
      "Epoch 501, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 502, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 503, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 504, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 505, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 506, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 507, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 508, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 509, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 510, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 511, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 512, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 513, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 514, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 515, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 516, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 517, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 518, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 519, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 520, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 521, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 522, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 523, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 524, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 525, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 526, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 527, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 528, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 529, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 530, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 531, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 532, train_loss: 0.000125, val_loss: 0.000254\n",
      "Epoch 533, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 534, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 535, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 536, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 537, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 538, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 539, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 540, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 541, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 542, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 543, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 544, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 545, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 546, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 547, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 548, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 549, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 550, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 551, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 552, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 553, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 554, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 555, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 556, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 557, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 558, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 559, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 560, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 561, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 562, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 563, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 564, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 565, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 566, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 567, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 568, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 569, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 570, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 571, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 572, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 573, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 574, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 575, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 576, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 577, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 578, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 579, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 580, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 581, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 582, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 583, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 584, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 585, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 586, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 587, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 588, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 589, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 590, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 591, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 592, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 593, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 594, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 595, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 596, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 597, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 598, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 599, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 600, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 601, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 602, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 603, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 604, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 605, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 606, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 607, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 608, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 609, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 610, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 611, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 612, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 613, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 614, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 615, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 616, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 617, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 618, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 619, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 620, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 621, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 622, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 623, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 624, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 625, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 626, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 627, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 628, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 629, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 630, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 631, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 632, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 633, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 634, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 635, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 636, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 637, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 638, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 639, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 640, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 641, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 642, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 643, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 644, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 645, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 646, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 647, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 648, train_loss: 0.000125, val_loss: 0.000253\n",
      "Epoch 649, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 650, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 651, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 652, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 653, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 654, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 655, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 656, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 657, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 658, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 659, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 660, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 661, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 662, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 663, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 664, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 665, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 666, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 667, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 668, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 669, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 670, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 671, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 672, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 673, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 674, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 675, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 676, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 677, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 678, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 679, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 680, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 681, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 682, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 683, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 684, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 685, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 686, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 687, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 688, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 689, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 690, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 691, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 692, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 693, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 694, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 695, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 696, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 697, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 698, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 699, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 700, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 701, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 702, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 703, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 704, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 705, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 706, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 707, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 708, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 709, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 710, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 711, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 712, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 713, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 714, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 715, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 716, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 717, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 718, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 719, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 720, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 721, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 722, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 723, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 724, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 725, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 726, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 727, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 728, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 729, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 730, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 731, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 732, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 733, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 734, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 735, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 736, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 737, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 738, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 739, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 740, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 741, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 742, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 743, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 744, train_loss: 0.000125, val_loss: 0.000252\n",
      "Epoch 745, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 746, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 747, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 748, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 749, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 750, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 751, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 752, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 753, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 754, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 755, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 756, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 757, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 758, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 759, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 760, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 761, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 762, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 763, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 764, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 765, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 766, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 767, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 768, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 769, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 770, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 771, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 772, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 773, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 774, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 775, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 776, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 777, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 778, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 779, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 780, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 781, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 782, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 783, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 784, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 785, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 786, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 787, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 788, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 789, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 790, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 791, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 792, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 793, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 794, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 795, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 796, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 797, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 798, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 799, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 800, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 801, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 802, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 803, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 804, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 805, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 806, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 807, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 808, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 809, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 810, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 811, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 812, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 813, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 814, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 815, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 816, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 817, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 818, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 819, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 820, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 821, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 822, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 823, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 824, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 825, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 826, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 827, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 828, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 829, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 830, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 831, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 832, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 833, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 834, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 835, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 836, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 837, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 838, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 839, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 840, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 841, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 842, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 843, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 844, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 845, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 846, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 847, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 848, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 849, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 850, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 851, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 852, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 853, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 854, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 855, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 856, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 857, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 858, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 859, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 860, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 861, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 862, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 863, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 864, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 865, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 866, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 867, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 868, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 869, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 870, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 871, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 872, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 873, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 874, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 875, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 876, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 877, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 878, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 879, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 880, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 881, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 882, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 883, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 884, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 885, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 886, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 887, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 888, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 889, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 890, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 891, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 892, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 893, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 894, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 895, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 896, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 897, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 898, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 899, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 900, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 901, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 902, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 903, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 904, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 905, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 906, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 907, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 908, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 909, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 910, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 911, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 912, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 913, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 914, train_loss: 0.000124, val_loss: 0.000252\n",
      "Epoch 915, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 916, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 917, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 918, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 919, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 920, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 921, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 922, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 923, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 924, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 925, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 926, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 927, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 928, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 929, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 930, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 931, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 932, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 933, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 934, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 935, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 936, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 937, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 938, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 939, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 940, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 941, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 942, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 943, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 944, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 945, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 946, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 947, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 948, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 949, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 950, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 951, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 952, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 953, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 954, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 955, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 956, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 957, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 958, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 959, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 960, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 961, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 962, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 963, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 964, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 965, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 966, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 967, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 968, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 969, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 970, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 971, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 972, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 973, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 974, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 975, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 976, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 977, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 978, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 979, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 980, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 981, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 982, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 983, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 984, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 985, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 986, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 987, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 988, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 989, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 990, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 991, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 992, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 993, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 994, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 995, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 996, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 997, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 998, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 999, train_loss: 0.000124, val_loss: 0.000251\n",
      "Epoch 1000, train_loss: 0.000124, val_loss: 0.000251\n"
     ]
    }
   ],
   "source": [
    "## Let's train the model\n",
    "EPOCHS = 1000\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    # Make predictions\n",
    "    y_pred = model(X_train).squeeze()\n",
    "\n",
    "    # Compute losses\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Reset gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Backward pass to calculate gradients\n",
    "    loss.backward()\n",
    "\n",
    "    # Update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute validation loss\n",
    "    y_val_pred = model(X_val).squeeze()\n",
    "    val_loss = criterion(y_val, y_val_pred)\n",
    "    epoch_val_loss = val_loss.item() / len(X_val)\n",
    "\n",
    "    # Store loss\n",
    "    epoch_loss = loss.item() / len(X_train)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, train_loss: {epoch_loss:.6f}, val_loss: {epoch_val_loss:.6f}\")\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_losses[3:], label = 'Training loss')\n",
    "plt.plot(val_losses[3:], label = 'Val loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
