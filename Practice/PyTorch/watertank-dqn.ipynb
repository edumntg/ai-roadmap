{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "from datetime import date\n",
    "\n",
    "DEFAULT_X = 8.0\n",
    "DEFAULT_Y = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System description\n",
    "We will simulate a water-tank level controller. The model will control the input voltage of the inflow pump, so it regulates the level inside the tank.\n",
    "\n",
    "The level in the tank is described as:\n",
    "\n",
    "$$H_{t+1} = H_{t} + \\Delta t * \\frac{P-Q}{A}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$P = bV$$\n",
    "$$Q = a\\sqrt{H}$$\n",
    "\n",
    "We define our reward function as:\n",
    "$$r = -|H-\\hat{H}|^{2}$$\n",
    "\n",
    "We are also testing with a percent difference function:\n",
    "\n",
    "$$r = -\\frac{|H-\\hat{H}|}{\\hat{H}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterTankEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = False\n",
    "\n",
    "    def __init__(self, td_params=None, seed=None, device=\"cpu\"):\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    @property\n",
    "    def td(self):\n",
    "        if self._td is None:\n",
    "            self._td = WaterTankEnv.gen_params(batch_size=[1])\n",
    "        \n",
    "        return self._td\n",
    "\n",
    "    # Static method to generate default values for parameters\n",
    "    @staticmethod\n",
    "    def gen_params(A = 20.0, a = 2.0, b = 5.0, batch_size=None) -> TensorDictBase:\n",
    "        \"\"\"Returns a ``tensordict`` containing the physical parameters such as gravitational force and torque or speed limits.\"\"\"\n",
    "        if batch_size is None:\n",
    "            batch_size = []\n",
    "        td = TensorDict(\n",
    "            {\n",
    "                \"params\": TensorDict(\n",
    "                    {\n",
    "                        \"max_voltage\": 120.0,\n",
    "                        \"min_voltage\": 0.0,\n",
    "                        \"max_H\": 15.0,\n",
    "                        \"min_H\": 1e-6,\n",
    "                        \"H_hat\": 10.0, # setpoint\n",
    "                        \"A\": A,\n",
    "                        \"a\": a,\n",
    "                        \"b\": b,\n",
    "                        \"dt\": 0.05,\n",
    "                        \"P_hat\": 0.0\n",
    "                    },\n",
    "                    [],\n",
    "                )\n",
    "            },\n",
    "            [],\n",
    "        )\n",
    "        if batch_size:\n",
    "            td = td.expand(batch_size).contiguous()\n",
    "        return td\n",
    "    \n",
    "    # Define the cost function here\n",
    "    @staticmethod\n",
    "    def cost(tensordict: TensorDict):\n",
    "        H = tensordict[\"H\"]\n",
    "        H_hat = tensordict[\"params\", \"H_hat\"]\n",
    "\n",
    "        return torch.abs(H - H_hat)/H_hat\n",
    "\n",
    "\n",
    "    # Step method\n",
    "    @staticmethod\n",
    "    def _step(tensordict):\n",
    "        H = tensordict[\"H\"]\n",
    "\n",
    "        # Pump and tank parameters\n",
    "        A = tensordict[\"params\", \"A\"] # area of tank\n",
    "        b = tensordict[\"params\", \"b\"] # parameter of pump\n",
    "        a = tensordict[\"params\", \"a\"] # parameter of output valve\n",
    "        H_hat = tensordict[\"params\", \"H_hat\"] # setpoint\n",
    "        P_hat = tensordict[\"params\", \"P_hat\"] # disturbance\n",
    "\n",
    "        dt = tensordict[\"params\", \"dt\"]\n",
    "        u = tensordict[\"action\"].squeeze(-1)\n",
    "        u = u.clamp(tensordict[\"params\", \"min_voltage\"], tensordict[\"params\", \"max_voltage\"])\n",
    "        \n",
    "        costs = WaterTankEnv.cost(tensordict)\n",
    "        #costs = torch.abs(H - H_hat)/H_hat\n",
    "\n",
    "        P = b*u + P_hat\n",
    "        Q = a*torch.sqrt(H)\n",
    "\n",
    "        # Compute new state using 4th-order Runge-Kutta method\n",
    "        # k1 = (P-Q)/A\n",
    "        # k2 = (P-Q)/A + dt*k1/2.0\n",
    "        # k3 = (P-Q)/A + dt*k2/2.0\n",
    "        # k4 = (P-Q)/A + dt*k3\n",
    "\n",
    "        # new_H = H + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4)\n",
    "\n",
    "        new_H = (\n",
    "            H + dt * (P - Q)/A\n",
    "        )\n",
    "        #print(new_H)\n",
    "\n",
    "        # Clamp between its range [min_H, max_H]\n",
    "        new_H = new_H.clamp(\n",
    "            tensordict[\"params\", \"min_H\"], tensordict[\"params\", \"max_H\"]\n",
    "        )\n",
    "\n",
    "        reward = -costs.view(*tensordict.shape, 1)\n",
    "        done = torch.zeros_like(reward, dtype=torch.bool)\n",
    "        out = TensorDict(\n",
    "            {\n",
    "                \"H\": new_H,\n",
    "                \"params\": tensordict[\"params\"],\n",
    "                \"reward\": reward,\n",
    "                \"done\": done,\n",
    "                \"reward\": -costs\n",
    "            },\n",
    "            tensordict.shape,\n",
    "        )\n",
    "        return out\n",
    "    \n",
    "    def _reset(self, tensordict):\n",
    "        if tensordict is None or tensordict.is_empty():\n",
    "            # if no ``tensordict`` is passed, we generate a single set of hyperparameters\n",
    "            # Otherwise, we assume that the input ``tensordict`` contains all the relevant\n",
    "            # parameters to get started.\n",
    "            tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "\n",
    "        high_H = torch.tensor(DEFAULT_X, device = self.device)\n",
    "        low_H = torch.tensor(1e-6, device = self.device)\n",
    "\n",
    "        # for non batch-locked environments, the input ``tensordict`` shape dictates the number\n",
    "        # of simulators run simultaneously. In other contexts, the initial\n",
    "        # random state's shape will depend upon the environment batch-size instead.\n",
    "\n",
    "        H = (\n",
    "            torch.rand(tensordict.shape, generator = self.rng, device = self.device)\n",
    "            * (high_H - low_H) + low_H\n",
    "        )\n",
    "\n",
    "        out = TensorDict(\n",
    "            {\n",
    "                \"H\": H,\n",
    "                \"params\": tensordict[\"params\"],\n",
    "            },\n",
    "            batch_size=tensordict.shape,\n",
    "        )\n",
    "        return out\n",
    "    \n",
    "    def _make_spec(self, td_params):\n",
    "        # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "        self.observation_spec = CompositeSpec(\n",
    "            H=BoundedTensorSpec(\n",
    "                low=td_params[\"params\", \"min_H\"],\n",
    "                high=td_params[\"params\", \"max_H\"],\n",
    "                shape=(),\n",
    "                dtype=torch.float32,\n",
    "            ),\n",
    "            # we need to add the ``params`` to the observation specs, as we want\n",
    "            # to pass it at each step during a rollout\n",
    "            params=make_composite_from_td(td_params[\"params\"]),\n",
    "            shape=(),\n",
    "        )\n",
    "        # since the environment is stateless, we expect the previous output as input.\n",
    "        # For this, ``EnvBase`` expects some state_spec to be available\n",
    "        self.state_spec = self.observation_spec.clone()\n",
    "        # action-spec will be automatically wrapped in input_spec when\n",
    "        # `self.action_spec = spec` will be called supported\n",
    "        self.action_spec = BoundedTensorSpec(\n",
    "            low=td_params[\"params\", \"min_voltage\"],\n",
    "            high=td_params[\"params\", \"max_voltage\"],\n",
    "            shape=(1,),\n",
    "            dtype=torch.float32,\n",
    "        )\n",
    "        self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "    def _set_seed(self, seed: Optional[int]):\n",
    "        rng = torch.manual_seed(seed)\n",
    "        self.rng = rng\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom function to convert a ``tensordict`` in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite\n",
    "        \n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:26:59,805 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "env = WaterTankEnv()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a brief look at out specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    H: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_voltage: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        min_voltage: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        max_H: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        min_H: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        H_hat: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        A: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        a: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        b: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        P_hat: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "state_spec: CompositeSpec(\n",
      "    H: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_voltage: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        min_voltage: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        max_H: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        min_H: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        H_hat: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        A: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        a: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        b: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        P_hat: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                A: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                H_hat: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                P_hat: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                a: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                b: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_voltage: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_voltage: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        A: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        H_hat: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        P_hat: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        a: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        b: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_voltage: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_voltage: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                A: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                H_hat: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                P_hat: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                a: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                b: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_voltage: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_H: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_voltage: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    env,\n",
    "    # ``Unsqueeze`` the observations that we will concatenate\n",
    "    UnsqueezeTransform(\n",
    "        unsqueeze_dim=-1,\n",
    "        in_keys=[\"H\"],\n",
    "        in_keys_inv=[\"H\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_transform = CatTensors(\n",
    "    in_keys=[\"H\"], dim=-1, out_key=\"observation\", del_keys=False\n",
    ")\n",
    "env.append_transform(cat_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 11:26:59,875 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data from rollout: TensorDict(\n",
      "    fields={\n",
      "        H: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        action: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                H: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        A: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        H_hat: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        P_hat: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        a: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        b: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        dt: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_H: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_voltage: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_H: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_voltage: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([100]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([100]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                A: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                H_hat: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                P_hat: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                a: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                b: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_H: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_voltage: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_H: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_voltage: Tensor(shape=torch.Size([100]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([100]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([100, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([100]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "def simple_rollout(steps=100):\n",
    "    # preallocate:\n",
    "    data = TensorDict({}, [steps])\n",
    "    # reset\n",
    "    _data = env.reset()\n",
    "    for i in range(steps):\n",
    "        _data[\"action\"] = env.action_spec.rand()\n",
    "        _data = env.step(_data)\n",
    "        data[i] = _data\n",
    "        _data = step_mdp(_data, keep_other=True)\n",
    "    return data\n",
    "\n",
    "\n",
    "print(\"data from rollout:\", simple_rollout(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        H: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                A: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                H_hat: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                P_hat: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                a: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                b: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_H: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_voltage: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_H: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_voltage: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "rand step (batch size of 10) TensorDict(\n",
      "    fields={\n",
      "        H: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        action: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                H: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        A: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        H_hat: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        P_hat: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        a: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        b: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        dt: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_H: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_voltage: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_H: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_voltage: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                A: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                H_hat: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                P_hat: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                a: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                b: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_H: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_voltage: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_H: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_voltage: Tensor(shape=torch.Size([10]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10  # number of environments to be executed in batch\n",
    "td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "print(\"reset (batch size of 10)\", td)\n",
    "td = env.rand_step(td)\n",
    "print(\"rand step (batch size of 10)\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout of len 3 (batch size of 10): TensorDict(\n",
      "    fields={\n",
      "        H: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        action: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                H: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                done: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                observation: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        A: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        H_hat: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        P_hat: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        a: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        b: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        dt: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_H: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_voltage: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_H: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        min_voltage: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([10, 3]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "            batch_size=torch.Size([10, 3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        observation: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                A: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                H_hat: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                P_hat: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                a: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                b: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                dt: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_H: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_voltage: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_H: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                min_voltage: Tensor(shape=torch.Size([10, 3]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([10, 3]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([10, 3, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
      "    batch_size=torch.Size([10, 3]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "rollout = env.rollout(\n",
    "    3,\n",
    "    auto_reset=False,  # we're executing the reset out of the ``rollout`` call\n",
    "    tensordict=env.reset(env.gen_params(batch_size=[batch_size])),\n",
    ")\n",
    "print(\"rollout of len 3 (batch size of 10):\", rollout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\lazy.py:181: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "env.set_seed(0)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(64),\n",
    "    nn.Tanh(),\n",
    "    nn.LazyLinear(1),\n",
    ")\n",
    "policy = TensorDictModule(\n",
    "    net,\n",
    "    in_keys=[\"observation\"],\n",
    "    out_keys=[\"action\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(policy.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reward: -0.3350, last reward: -0.1289, gradient norm:  1.507:  28%|██▊       | 434/1562 [07:08<18:33,  1.01it/s] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m rollout \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mrollout(\u001b[38;5;241m500\u001b[39m, policy, tensordict\u001b[38;5;241m=\u001b[39minit_td, auto_reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m traj_return \u001b[38;5;241m=\u001b[39m rollout[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m---> 11\u001b[0m \u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtraj_return\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m gn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(net\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "T_max = 50_000\n",
    "pbar = tqdm.tqdm(range(T_max // batch_size))\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, T_max)\n",
    "logs = defaultdict(list)\n",
    "\n",
    "for _ in pbar:\n",
    "    init_td = env.reset(env.gen_params(batch_size=[batch_size]))\n",
    "    rollout = env.rollout(500, policy, tensordict=init_td, auto_reset=False)\n",
    "    traj_return = rollout[\"next\", \"reward\"].mean()\n",
    "    (-traj_return).backward()\n",
    "    gn = torch.nn.utils.clip_grad_norm_(net.parameters(), 1.0)\n",
    "    optim.step()\n",
    "    optim.zero_grad()\n",
    "    pbar.set_description(\n",
    "        f\"reward: {traj_return: 4.4f}, \"\n",
    "        f\"last reward: {rollout[..., -1]['next', 'reward'].mean(): 4.4f}, gradient norm: {gn: 4.4}\"\n",
    "    )\n",
    "    logs[\"return\"].append(traj_return.item())\n",
    "    logs[\"last_reward\"].append(rollout[..., -1][\"next\", \"reward\"].mean().item())\n",
    "    logs[\"state_value\"].append(rollout[\"H\"])\n",
    "    scheduler.step()\n",
    "\n",
    "\n",
    "def plot():\n",
    "    import matplotlib\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    is_ipython = \"inline\" in matplotlib.get_backend()\n",
    "    if is_ipython:\n",
    "        from IPython import display\n",
    "\n",
    "    with plt.ion():\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(logs[\"return\"])\n",
    "        plt.title(\"returns\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(logs[\"last_reward\"])\n",
    "        plt.title(\"last reward\")\n",
    "        plt.xlabel(\"iteration\")\n",
    "        if is_ipython:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "torch.save(policy, f\"model_{date.today()}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "policy = torch.load(f\"model_{date.today()}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = 200 # seconds\n",
    "dt = 0.05\n",
    "N = int(tf // dt)\n",
    "\n",
    "# Generate parameters\n",
    "sim_td = WaterTankEnv.gen_params(batch_size = [1])\n",
    "sim_td = env.reset(sim_td) # System is at it starting point\n",
    "\n",
    "sim_events = [\n",
    "    # variable, value, time\n",
    "    (\"H_hat\", 20, 50),\n",
    "    #(\"P_hat\", 37, 100)\n",
    "]\n",
    "\n",
    "#H_vals = []\n",
    "H_ref = []\n",
    "t_vals = []\n",
    "H_vals = TensorDict({}, batch_size=[N])\n",
    "result = TensorDict({}, [N])\n",
    "for i in range(N):\n",
    "    ti = i*dt\n",
    "\n",
    "    # Check events\n",
    "    for event in sim_events:\n",
    "        if ti >= event[2]:\n",
    "            sim_td[\"params\", event[0]] = torch.tensor([event[1]], dtype=torch.float32)\n",
    "\n",
    "    # Based on current state, get optimal action from policy\n",
    "    action = policy(sim_td)[\"action\"].squeeze(dim=1) # tensor([value])\n",
    "\n",
    "    # Assign action to tensordict\n",
    "    sim_td[\"action\"] = action\n",
    "\n",
    "    # Make step in simulation with this action value\n",
    "    sim_td = env.step(sim_td)\n",
    "\n",
    "    # Get new H\n",
    "    new_H = sim_td[\"next\", \"observation\"]\n",
    "    H_ref = sim_td[\"params\", \"H_hat\"]\n",
    "\n",
    "    sim_td = step_mdp(sim_td, keep_other= True) # Remove the \"next\" td and move its values to the main \"td\"\n",
    "    \n",
    "\n",
    "    #H_vals.append(sim_td[\"next\", \"H\"].item()) # New H value\n",
    "    result[i] = TensorDict({\n",
    "        \"H\": new_H,\n",
    "        \"H_hat\": H_ref,\n",
    "        \"action\": action\n",
    "        }, [1])\n",
    "    #H_vals[i] = new_H\n",
    "    #H_ref.append(sim_td[\"params\", \"H_hat\"].item())\n",
    "    t_vals.append(ti)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(t_vals, result[\"H\"].squeeze(dim=1).detach().numpy(), label = 'state')\n",
    "plt.plot(t_vals, result[\"H_hat\"].squeeze(dim=1).detach().numpy(), label = 'setpoint')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(t_vals, result[\"action\"].squeeze(dim=1).detach().numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_td[\"params\", \"H_hat\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.0043]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_td[\"observation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        H: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        action: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        params: TensorDict(\n",
       "            fields={\n",
       "                A: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                H_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                P_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                a: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                b: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_out = policy(sim_td)\n",
    "nn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        H: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        action: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        params: TensorDict(\n",
       "            fields={\n",
       "                A: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                H_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                P_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                a: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                b: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_td[\"action\"] = nn_out[\"action\"]\n",
    "sim_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        H: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                H: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                params: TensorDict(\n",
       "                    fields={\n",
       "                        A: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        H_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        P_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        a: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        b: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        min_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        min_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        params: TensorDict(\n",
       "            fields={\n",
       "                A: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                H_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                P_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                a: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                b: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_td = WaterTankEnv.gen_params(batch_size = [1])\n",
    "sim_td = env.reset(sim_td)\n",
    "action = policy(sim_td)[\"action\"].squeeze(dim=1)\n",
    "sim_td[\"action\"] = action\n",
    "out = env.step(sim_td)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        H: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "        next: TensorDict(\n",
       "            fields={\n",
       "                H: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                done: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
       "                observation: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                params: TensorDict(\n",
       "                    fields={\n",
       "                        A: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        H_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        P_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        a: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        b: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        max_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        min_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                        min_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "                    batch_size=torch.Size([1]),\n",
       "                    device=None,\n",
       "                    is_shared=False),\n",
       "                reward: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        observation: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        params: TensorDict(\n",
       "            fields={\n",
       "                A: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                H_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                P_hat: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                a: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                b: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                dt: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                max_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_H: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "                min_voltage: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=None,\n",
       "            is_shared=False),\n",
       "        terminated: Tensor(shape=torch.Size([1, 1]), device=cpu, dtype=torch.bool, is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sim_td = env.step(sim_td)\n",
    "new_sim_td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[12.8610]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sim_td[\"next\", \"observation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.4822])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_spec.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-39.3415], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
