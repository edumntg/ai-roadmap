{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Optional\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import tqdm\n",
    "from tensordict import TensorDict, TensorDictBase\n",
    "from tensordict.nn import TensorDictModule\n",
    "from torch import nn\n",
    "\n",
    "from torchrl.data import BoundedTensorSpec, CompositeSpec, UnboundedContinuousTensorSpec\n",
    "from torchrl.envs import (\n",
    "    CatTensors,\n",
    "    EnvBase,\n",
    "    Transform,\n",
    "    TransformedEnv,\n",
    "    UnsqueezeTransform,\n",
    ")\n",
    "from torchrl.envs.transforms.transforms import _apply_to_composite\n",
    "from torchrl.envs.utils import check_env_specs, step_mdp\n",
    "\n",
    "DEFAULT_X = np.pi\n",
    "DEFAULT_Y = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _step(tensordict):\n",
    "    th, thdot = tensordict[\"th\"], tensordict[\"thdot\"]  # th := theta\n",
    "\n",
    "    g_force = tensordict[\"params\", \"g\"]\n",
    "    mass = tensordict[\"params\", \"m\"]\n",
    "    length = tensordict[\"params\", \"l\"]\n",
    "    dt = tensordict[\"params\", \"dt\"]\n",
    "    u = tensordict[\"action\"].squeeze(-1)\n",
    "    u = u.clamp(-tensordict[\"params\", \"max_torque\"], tensordict[\"params\", \"max_torque\"])\n",
    "    costs = angle_normalize(th) ** 2 + 0.1 * thdot**2 + 0.001 * (u**2)\n",
    "\n",
    "    new_thdot = (\n",
    "        thdot\n",
    "        + (3 * g_force / (2 * length) * th.sin() + 3.0 / (mass * length**2) * u) * dt\n",
    "    )\n",
    "    new_thdot = new_thdot.clamp(\n",
    "        -tensordict[\"params\", \"max_speed\"], tensordict[\"params\", \"max_speed\"]\n",
    "    )\n",
    "    new_th = th + new_thdot * dt\n",
    "    reward = -costs.view(*tensordict.shape, 1)\n",
    "    done = torch.zeros_like(reward, dtype=torch.bool)\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"th\": new_th,\n",
    "            \"thdot\": new_thdot,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "            \"reward\": reward,\n",
    "            \"done\": done,\n",
    "        },\n",
    "        tensordict.shape,\n",
    "    )\n",
    "    return out\n",
    "\n",
    "\n",
    "def angle_normalize(x):\n",
    "    return ((x + torch.pi) % (2 * torch.pi)) - torch.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reset(self, tensordict):\n",
    "    if tensordict is None or tensordict.is_empty():\n",
    "        # if no ``tensordict`` is passed, we generate a single set of hyperparameters\n",
    "        # Otherwise, we assume that the input ``tensordict`` contains all the relevant\n",
    "        # parameters to get started.\n",
    "        tensordict = self.gen_params(batch_size=self.batch_size)\n",
    "\n",
    "    high_th = torch.tensor(DEFAULT_X, device=self.device)\n",
    "    high_thdot = torch.tensor(DEFAULT_Y, device=self.device)\n",
    "    low_th = -high_th\n",
    "    low_thdot = -high_thdot\n",
    "\n",
    "    # for non batch-locked environments, the input ``tensordict`` shape dictates the number\n",
    "    # of simulators run simultaneously. In other contexts, the initial\n",
    "    # random state's shape will depend upon the environment batch-size instead.\n",
    "    th = (\n",
    "        torch.rand(tensordict.shape, generator=self.rng, device=self.device)\n",
    "        * (high_th - low_th)\n",
    "        + low_th\n",
    "    )\n",
    "    thdot = (\n",
    "        torch.rand(tensordict.shape, generator=self.rng, device=self.device)\n",
    "        * (high_thdot - low_thdot)\n",
    "        + low_thdot\n",
    "    )\n",
    "    out = TensorDict(\n",
    "        {\n",
    "            \"th\": th,\n",
    "            \"thdot\": thdot,\n",
    "            \"params\": tensordict[\"params\"],\n",
    "        },\n",
    "        batch_size=tensordict.shape,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_spec(self, td_params):\n",
    "    # Under the hood, this will populate self.output_spec[\"observation\"]\n",
    "    self.observation_spec = CompositeSpec(\n",
    "        th=BoundedTensorSpec(\n",
    "            low=-torch.pi,\n",
    "            high=torch.pi,\n",
    "            shape=(),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        thdot=BoundedTensorSpec(\n",
    "            low=-td_params[\"params\", \"max_speed\"],\n",
    "            high=td_params[\"params\", \"max_speed\"],\n",
    "            shape=(),\n",
    "            dtype=torch.float32,\n",
    "        ),\n",
    "        # we need to add the ``params`` to the observation specs, as we want\n",
    "        # to pass it at each step during a rollout\n",
    "        params=make_composite_from_td(td_params[\"params\"]),\n",
    "        shape=(),\n",
    "    )\n",
    "    # since the environment is stateless, we expect the previous output as input.\n",
    "    # For this, ``EnvBase`` expects some state_spec to be available\n",
    "    self.state_spec = self.observation_spec.clone()\n",
    "    # action-spec will be automatically wrapped in input_spec when\n",
    "    # `self.action_spec = spec` will be called supported\n",
    "    self.action_spec = BoundedTensorSpec(\n",
    "        low=-td_params[\"params\", \"max_torque\"],\n",
    "        high=td_params[\"params\", \"max_torque\"],\n",
    "        shape=(1,),\n",
    "        dtype=torch.float32,\n",
    "    )\n",
    "    self.reward_spec = UnboundedContinuousTensorSpec(shape=(*td_params.shape, 1))\n",
    "\n",
    "\n",
    "def make_composite_from_td(td):\n",
    "    # custom function to convert a ``tensordict`` in a similar spec structure\n",
    "    # of unbounded values.\n",
    "    composite = CompositeSpec(\n",
    "        {\n",
    "            key: make_composite_from_td(tensor)\n",
    "            if isinstance(tensor, TensorDictBase)\n",
    "            else UnboundedContinuousTensorSpec(\n",
    "                dtype=tensor.dtype, device=tensor.device, shape=tensor.shape\n",
    "            )\n",
    "            for key, tensor in td.items()\n",
    "        },\n",
    "        shape=td.shape,\n",
    "    )\n",
    "    return composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_seed(self, seed: Optional[int]):\n",
    "    rng = torch.manual_seed(seed)\n",
    "    self.rng = rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_params(g=10.0, batch_size=None) -> TensorDictBase:\n",
    "    \"\"\"Returns a ``tensordict`` containing the physical parameters such as gravitational force and torque or speed limits.\"\"\"\n",
    "    if batch_size is None:\n",
    "        batch_size = []\n",
    "    td = TensorDict(\n",
    "        {\n",
    "            \"params\": TensorDict(\n",
    "                {\n",
    "                    \"max_speed\": 8,\n",
    "                    \"max_torque\": 2.0,\n",
    "                    \"dt\": 0.05,\n",
    "                    \"g\": g,\n",
    "                    \"m\": 1.0,\n",
    "                    \"l\": 1.0,\n",
    "                },\n",
    "                [],\n",
    "            )\n",
    "        },\n",
    "        [],\n",
    "    )\n",
    "    if batch_size:\n",
    "        td = td.expand(batch_size).contiguous()\n",
    "    return td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PendulumEnv(EnvBase):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\"human\", \"rgb_array\"],\n",
    "        \"render_fps\": 30,\n",
    "    }\n",
    "    batch_locked = False\n",
    "\n",
    "    def __init__(self, td_params=None, seed=None, device=\"cpu\"):\n",
    "        if td_params is None:\n",
    "            td_params = self.gen_params()\n",
    "\n",
    "        super().__init__(device=device, batch_size=[])\n",
    "        self._make_spec(td_params)\n",
    "        if seed is None:\n",
    "            seed = torch.empty((), dtype=torch.int64).random_().item()\n",
    "        self.set_seed(seed)\n",
    "\n",
    "    # Helpers: _make_step and gen_params\n",
    "    gen_params = staticmethod(gen_params)\n",
    "    _make_spec = _make_spec\n",
    "\n",
    "    # Mandatory methods: _step, _reset and _set_seed\n",
    "    _reset = _reset\n",
    "    _step = staticmethod(_step)\n",
    "    _set_seed = _set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 14:02:13,335 [torchrl][INFO] check_env_specs succeeded!\n"
     ]
    }
   ],
   "source": [
    "env = PendulumEnv()\n",
    "check_env_specs(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "observation_spec: CompositeSpec(\n",
      "    th: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    thdot: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_speed: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        max_torque: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        g: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        m: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        l: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "state_spec: CompositeSpec(\n",
      "    th: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    thdot: BoundedTensorSpec(\n",
      "        shape=torch.Size([]),\n",
      "        space=ContinuousBox(\n",
      "            low=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "            high=Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "        device=cpu,\n",
      "        dtype=torch.float32,\n",
      "        domain=continuous),\n",
      "    params: CompositeSpec(\n",
      "        max_speed: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.int64,\n",
      "            domain=discrete),\n",
      "        max_torque: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        dt: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        g: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        m: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous),\n",
      "        l: UnboundedContinuousTensorSpec(\n",
      "            shape=torch.Size([]),\n",
      "            space=None,\n",
      "            device=cpu,\n",
      "            dtype=torch.float32,\n",
      "            domain=continuous), device=cpu, shape=torch.Size([])), device=cpu, shape=torch.Size([]))\n",
      "reward_spec: UnboundedContinuousTensorSpec(\n",
      "    shape=torch.Size([1]),\n",
      "    space=ContinuousBox(\n",
      "        low=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True),\n",
      "        high=Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, contiguous=True)),\n",
      "    device=cpu,\n",
      "    dtype=torch.float32,\n",
      "    domain=continuous)\n"
     ]
    }
   ],
   "source": [
    "print(\"observation_spec:\", env.observation_spec)\n",
    "print(\"state_spec:\", env.state_spec)\n",
    "print(\"reward_spec:\", env.reward_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reset tensordict TensorDict(\n",
      "    fields={\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.reset()\n",
    "print(\"reset tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random step tensordict TensorDict(\n",
      "    fields={\n",
      "        action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                params: TensorDict(\n",
      "                    fields={\n",
      "                        dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        g: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        l: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        m: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                        max_speed: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                        max_torque: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "                    batch_size=torch.Size([]),\n",
      "                    device=None,\n",
      "                    is_shared=False),\n",
      "                reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "                th: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                thdot: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        params: TensorDict(\n",
      "            fields={\n",
      "                dt: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                g: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                l: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                m: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "                max_speed: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.int64, is_shared=False),\n",
      "                max_torque: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False),\n",
      "        terminated: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.bool, is_shared=False),\n",
      "        th: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False),\n",
      "        thdot: Tensor(shape=torch.Size([]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n"
     ]
    }
   ],
   "source": [
    "td = env.rand_step(td)\n",
    "print(\"random step tensordict\", td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TransformedEnv(\n",
    "    env,\n",
    "    # ``Unsqueeze`` the observations that we will concatenate\n",
    "    UnsqueezeTransform(\n",
    "        unsqueeze_dim=-1,\n",
    "        in_keys=[\"th\", \"thdot\"],\n",
    "        in_keys_inv=[\"th\", \"thdot\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.sin()\n",
    "\n",
    "    # The transform must also modify the data at reset time\n",
    "    def _reset(\n",
    "        self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase\n",
    "    ) -> TensorDictBase:\n",
    "        return self._call(tensordict_reset)\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "class CosTransform(Transform):\n",
    "    def _apply_transform(self, obs: torch.Tensor) -> None:\n",
    "        return obs.cos()\n",
    "\n",
    "    # The transform must also modify the data at reset time\n",
    "    def _reset(\n",
    "        self, tensordict: TensorDictBase, tensordict_reset: TensorDictBase\n",
    "    ) -> TensorDictBase:\n",
    "        return self._call(tensordict_reset)\n",
    "\n",
    "    # _apply_to_composite will execute the observation spec transform across all\n",
    "    # in_keys/out_keys pairs and write the result in the observation_spec which\n",
    "    # is of type ``Composite``\n",
    "    @_apply_to_composite\n",
    "    def transform_observation_spec(self, observation_spec):\n",
    "        return BoundedTensorSpec(\n",
    "            low=-1,\n",
    "            high=1,\n",
    "            shape=observation_spec.shape,\n",
    "            dtype=observation_spec.dtype,\n",
    "            device=observation_spec.device,\n",
    "        )\n",
    "\n",
    "\n",
    "t_sin = SinTransform(in_keys=[\"th\"], out_keys=[\"sin\"])\n",
    "t_cos = CosTransform(in_keys=[\"th\"], out_keys=[\"cos\"])\n",
    "env.append_transform(t_sin)\n",
    "env.append_transform(t_cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
